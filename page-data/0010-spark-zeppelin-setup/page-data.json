{"componentChunkName":"component---src-templates-blog-post-js","path":"/0010-spark-zeppelin-setup/","result":{"data":{"site":{"siteMetadata":{"title":"Blog of Sebastian Häni"}},"markdownRemark":{"id":"ad989470-db50-55fe-9ef8-228a266dce4d","excerpt":"This article describes how to setup Spark and Zeppelin either on your own machine or on a server or cloud. Spark and Zeppelin are big software products with a…","html":"<p>This article describes how to setup Spark and Zeppelin either on your own machine or on a server or cloud. Spark and Zeppelin are big software products with a wide variety of plugins, interpreters, etc. Finding the compatible versions, Dockerfiles, configs, etc. for a simple setup can be daunting. This here might help you to deploy and play around with Spark on your local machine or create a server setup as a ground to do some demos or proof of concepts. In this setup we will use the local file system and not a distributed one. When you use Spark in a production grade setup, you want to scale your filesystem and workers. But, our goal here is to create a playground environment.</p>\n<p>This blog post refers to this accompanying GitHub repository:</p>\n<p style=\"text-align: center\">\n<a href=\"https://github.com/sebastianhaeni/spark-zeppelin-docker\" rel=\"noopener noreferrer\" target=\"_blank\">sebastianhaeni/spark-zeppelin-docker</a>\n</p>\n<h2 id=\"what-is-spark-and-zeppelin\" style=\"position:relative;\"><a href=\"#what-is-spark-and-zeppelin\" aria-label=\"what is spark and zeppelin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What is Spark and Zeppelin</h2>\n<p><strong><a href=\"https://spark.apache.org/\">Apache Spark</a></strong> is an engine to process your data in a highly parallel and fault tolerant way. You can submit programs as Spark jobs which will be run on Spark cluster consisting of at least one worker node connecting to a distributed storage. The programs can be written most famously in Python (<a href=\"https://spark.apache.org/docs/latest/api/python/\">PySpark</a>) or <a href=\"https://www.scala-lang.org/\">Scala</a> using the <a href=\"https://en.wikipedia.org/wiki/MapReduce\">MapReduce</a> paradigm. Alternatively, you can use <a href=\"https://spark.apache.org/sql/\">Spark SQL</a> to submit SQL queries and retrieve the query result. However, the user interface of the Spark master and worker nodes merely display running jobs and logs. There is no user interface to submit jobs. This calls for a Notebook solution.</p>\n<p><strong><a href=\"https://zeppelin.apache.org/\">Apache Zeppelin</a></strong> is a notebook web application like <a href=\"https://jupyterlab.readthedocs.io/en/stable/\">JupyterLab</a> focusing on notebook collaboration. Both tools cover a similar feature set. There are many opinions out there on which tool is better. Please make your own opinion about it. This article just covers how to install it. Zeppelin fits quite nicely into the Spark world, but you can achieve the same results using JupyterLab.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.75675675675676%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABcSAAAXEgFnn9JSAAACKUlEQVR42kWS605TQRSF+4g+hK+hBMVo/GGMGkUTTPCPguAlKvGSGDREMbbcokAAW4gJpbWlPdc5c/3MnlY8ycqZmb1m7T17r9q9pU1mPmxz/90Pri40uP58g0vzDS4/XWNqcZ0rixuj9cIaE3MNluqHbDW71PdP2Gz12Drs82h5h4nHX5mab1Dr9/qossCZCqMV3mqCs4Tg45kAAgQPweG9Q2uNtZbgPV7gLGWeYrWilmYZZVFgnY8ErQ2V9aiq4vi4TZ7nyOd9oNIG6z1ZlkUYo3HOUWmNti7Ga1lR0TnpkvQ6kZQMBqRpEYlpmjIcDuN5WZYo7XDex1hRFDGZUgpjLEmhMcZQK5WhLBVlMuBPr03WO8FoHSsSgojleQHesttO2Dg6jRUnSUKhHcZJK0IUFdQkozx5fXuPL6+mac2+prLEvkmvRFQ+4V148ZPbH3/FvVTcSRTK2CgYRNRaahL8vvqNOzdvUZ97ybPJBX7vHcdLRvo5FjzqF5yfbTCzchj3wyQlVeZMML5IBD2Qd/oM5+u0Jt/y5tpFOocH8VJVVXGaqbLceL/PuburTH9qxtjpMMVYT6ktxrrRs0XQygawzQGnT3bIjtpiEkLM6OimiuXdLg8+N3m40mLloB/5WV7iQ8DKlK2nUJpSVTIUFcduvMMEh5X/2GcSE5LYIwRH8CN/Cl9VKvb3X5+j3cQ24jdnHc7a/3AuwozXdrwewcVkZxj7UHSkgL8d+TwAAPJNLwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Apache Zeppelin Notebook\"\n        title=\"\"\n        src=\"/blog/static/6c98a066d067a1daace2fc3c41b7b310/fcda8/zeppelin.png\"\n        srcset=\"/blog/static/6c98a066d067a1daace2fc3c41b7b310/12f09/zeppelin.png 148w,\n/blog/static/6c98a066d067a1daace2fc3c41b7b310/e4a3f/zeppelin.png 295w,\n/blog/static/6c98a066d067a1daace2fc3c41b7b310/fcda8/zeppelin.png 590w,\n/blog/static/6c98a066d067a1daace2fc3c41b7b310/efc66/zeppelin.png 885w,\n/blog/static/6c98a066d067a1daace2fc3c41b7b310/c83ae/zeppelin.png 1180w,\n/blog/static/6c98a066d067a1daace2fc3c41b7b310/0e904/zeppelin.png 1384w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p style=\"text-align: center\">Image Source: <a href=\"https://zeppelin.apache.org/\">zeppelin.apache.org</a></p>\n<h2 id=\"setup\" style=\"position:relative;\"><a href=\"#setup\" aria-label=\"setup permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setup</h2>\n<p>This diagram shows all the Docker containers we will setup:\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 46.621621621621614%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdUlEQVR42n2RW07DMBBFXYpAldgQawCJlbAZ+GMz5YfnEpKPtGqbPtLUdRw/Y2fQdYtUgdSRrmaU2GeuZxj7E0Q0OJaDsiw/iIjCIfpTOed6rXWStbbHuaZpHDsHdM594qBzLsYYCeq6LmXnHG02G9putwDhGLVt688Bh1rrL2MMGWNiURS0WCzIe09aa7gma20SmvR9T+v12gNwOR6Pk4hoeMIeAYjOWusIJ/v9Pjlr2zaBUKMhAq6n0+l/h8e4ADCE8E6HiHD2C5FSJgkhACHOOSmlaD6fezabzZ6zLHsqiuJluVw+YnaMsWvG2FUIIS2Fcx6rqiIIFwEADNA8z1ONZpxzz2AZQ8dFKeUrY+zmqBHn/Bv/lVIR81utVmmGeDrAcItRAIy6aRrPJpPJvRDibrfbPeR5fnvy7EHXdWnL1tq0ZSwCCwAQruq6pizLUsZ3IcTZLQ+klG8AGmOcUipAxpigtQ5VVQXOeSjLErnDWOq6Nj9X7QAoY+Fq1AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"System Components\"\n        title=\"\"\n        src=\"/blog/static/c9bf1aca3bdedff69cea15257a9b2655/fcda8/system-components.drawio.png\"\n        srcset=\"/blog/static/c9bf1aca3bdedff69cea15257a9b2655/12f09/system-components.drawio.png 148w,\n/blog/static/c9bf1aca3bdedff69cea15257a9b2655/e4a3f/system-components.drawio.png 295w,\n/blog/static/c9bf1aca3bdedff69cea15257a9b2655/fcda8/system-components.drawio.png 590w,\n/blog/static/c9bf1aca3bdedff69cea15257a9b2655/c7dcc/system-components.drawio.png 641w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h2 id=\"instructions\" style=\"position:relative;\"><a href=\"#instructions\" aria-label=\"instructions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Instructions</h2>\n<p>Note: You need to configure Docker to have at least 4 GB of memory.</p>\n<ol>\n<li>Clone this repo <code class=\"language-text\">git clone https://github.com/sebastianhaeni/spark-zeppelin-docker.git</code></li>\n<li>Build the base image <code class=\"language-text\">docker build -f Dockerfile_base -t registry.local:5000/spark-zeppelin-demo/spark_base:latest .</code></li>\n<li>Build the remaining images <code class=\"language-text\">docker compose build</code></li>\n<li>Append the following to your <code class=\"language-text\">/etc/hosts</code> (Linux &#x26; MacOS) / <code class=\"language-text\">C:\\Windows\\System32\\drivers\\etc\\hosts</code> (Windows) file\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">127.0.0.1 zeppelin.local\n127.0.0.1 spark-ui-proxy.local</code></pre></div>\n</li>\n<li>Run with <code class=\"language-text\">docker compose up</code></li>\n<li>Open <a href=\"http://zeppelin.local/\">http://zeppelin.local/</a> in your browser to access Zeppelin</li>\n<li>Open <a href=\"http://spark-ui-proxy.local/\">http://spark-ui-proxy.local/</a> in your browser to access Spark</li>\n</ol>\n<p>And there you go. An example notebook is included as well to get you going.</p>\n<h2 id=\"reverse-proxy\" style=\"position:relative;\"><a href=\"#reverse-proxy\" aria-label=\"reverse proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reverse Proxy</h2>\n<p>The reverse proxy allows us to proxy to an internal container by server name.\nSo, we don’t have to map ports from the internal Docker network and we don’t have\nto remember names.</p>\n<p>To make this possible, we also need a custom Python web server that transforms the responses from Spark-Master and Spark-Worker.\nThey do not support reverse proxies out of the box (no support for X-Forwarded-For etc.), thus we rewrite the <code class=\"language-text\">&lt;a></code> links to\nthe correct URLs.</p>\n<h2 id=\"spark-and-zeppelin\" style=\"position:relative;\"><a href=\"#spark-and-zeppelin\" aria-label=\"spark and zeppelin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark and Zeppelin</h2>\n<h3 id=\"base-image\" style=\"position:relative;\"><a href=\"#base-image\" aria-label=\"base image permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Base Image</h3>\n<p>The Spark and Zeppelin images both depend on a base image, that we have to build beforehand.</p>\n<p>This image contains:</p>\n<ul>\n<li>JDK</li>\n<li>Scala</li>\n<li>Anaconda &#x26; Python</li>\n<li>Apache Spark</li>\n<li>Apache Zeppelin</li>\n</ul>\n<p>The reason why we create a single image with both Spark and Zeppelin, is that Spark needs\nsome JARs from Zeppelin (namely the spark interpreter jar) and Zeppelin needs some Spark JARs\nto connect to it. Also, Spark needs Anaconda (Python) to run PySpark. Zeppelin has a pure Python\ninterpreter that also needs Anaconda (to be able to achieve something meaningful).</p>\n<p>If you need to add another Python package to the image, you can do so either with <code class=\"language-text\">conda install</code>\nor <code class=\"language-text\">pip install</code> at the end of <code class=\"language-text\">Dockerfile_base</code>. Please be sure to rebuild the images\nafter doing so.</p>\n<h3 id=\"apache-spark\" style=\"position:relative;\"><a href=\"#apache-spark\" aria-label=\"apache spark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Apache Spark</h3>\n<p>The current configuration will create the following 3 containers:</p>\n<ul>\n<li>spark-master: Spark Master Node where workers connect</li>\n<li>spark-worker-1: A worker node, connecting to the master. Could be scaled.\n<ul>\n<li>Please note that the amount of CPU cores and memory to be reserved by the worker are defined in <code class=\"language-text\">Dockerfile_worker</code>\nand can be optionally overwritten by environment variables.</li>\n</ul>\n</li>\n<li>spark-ui-proxy: To access the nodes’ web UI, we need to transform the content with correct URLs (they don’t properly support reverse proxies)</li>\n</ul>\n<p>Please note that the Spark nodes have a volume mapping to <code class=\"language-text\">./data</code> . This is where you can place files to read in your Zeppelin notebook.\nAn example file is already provided.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token operator\">%</span>pyspark\ndf <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">(</span><span class=\"token string\">\"/srv/data/example/people.json\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"apache-zeppelin\" style=\"position:relative;\"><a href=\"#apache-zeppelin\" aria-label=\"apache zeppelin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Apache Zeppelin</h3>\n<p>Zeppelin will be connected to the Spark Master (Spark Interpreter) once you run the first Spark cell in a notebook.</p>\n<h3 id=\"compatibility-issues\" style=\"position:relative;\"><a href=\"#compatibility-issues\" aria-label=\"compatibility issues permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Compatibility Issues</h3>\n<p>Please note that Spark, Zeppelin, Python, JDK, Scala have to be compatible to each other.\nIn the current setup, these have been tested and matched to each other. For example, this would\nnot work:</p>\n<ul>\n<li>Upgrade from JDK 1.8 to e.g. 11. You will run into some class not found issues when running Zeppelin.</li>\n<li>Upgrade from Python 3.7 to Python 3.8. You will notice weird errors when running a PySpark script.</li>\n</ul>\n<p>So if there’s a need to upgrade, please reserve enough time to test the compatibility between those\nsystems well enough.</p>\n<p>A good approach can be a test notebook in Zeppelin containing blocks with Scala, Python, PySpark and\nSQL interpreters. Run them all successfully, and you basically proved that the system works.</p>","fields":{"slug":"/0010-spark-zeppelin-setup/"},"frontmatter":{"title":"Setting up Apache Spark and Zeppelin","date":"May 16, 2021","description":null,"tags":["DevOps","ML"]}}},"pageContext":{"slug":"/0010-spark-zeppelin-setup/","previous":{"fields":{"slug":"/0009-orgazining-code-reviews/"},"frontmatter":{"title":"Orgazining optimized code reviews in your team","tags":["Agile"]}},"next":{"fields":{"slug":"/0011-opentelemetry-intro/"},"frontmatter":{"title":"OpenTelemetry Introduction","tags":["DevOps","Tracing","Monitoring"]}}}},"staticQueryHashes":["3274528899","3333504701"],"slicesMap":{}}